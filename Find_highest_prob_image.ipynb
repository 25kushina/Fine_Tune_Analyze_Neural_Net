{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import *\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from random import sample\n",
    "from numpy import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from caffe_classes import class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3 # my classes (1000 # ImageNet)\n",
    "net_in = zeros((1, 227,227,3)).astype(float32)\n",
    "net_out = zeros((1, n_classes))\n",
    "xdim = net_in.shape[1:]\n",
    "ydim = net_out.shape[1]\n",
    "net_data = load(\"fine_tuned_net.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(w):\n",
    "    w = np.array(w)\n",
    "    maxes = np.amax(w, axis=1)\n",
    "    maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "    e = np.exp(w/maxes) # supposed to be minus maxes (max trick), but values were still too high\n",
    "    dist = e / np.sum(e, axis=1)[:,None]\n",
    "    return dist\n",
    "\n",
    "def next_batch_not_rand(step,batch_size,files):    \n",
    "    #files = sample(files, len(files))\n",
    "    files = files[(step-1)*batch_size:step*batch_size]\n",
    "    batch_x = np.ndarray([batch_size,227, 227, 3])\n",
    "    batch_y = np.zeros((batch_size, 3))\n",
    "    batch_names =[]\n",
    "    i = 0\n",
    "    for fname in files:\n",
    "        img = (imread(join(ImgPath, fname))[:,:,:3]).astype(float32)\n",
    "        img = img - mean(img)\n",
    "        #img = np.reshape(img,(1,227*227*3))        \n",
    "        batch_x[i] = img\n",
    "        if \"cat\" in fname:\n",
    "            batch_y[i][0] = 1\n",
    "        if \"dog\" in fname:\n",
    "            batch_y[i][1] = 1\n",
    "        if \"flower\" in fname:\n",
    "            batch_y[i][2] = 1\n",
    "        batch_names.append(fname)\n",
    "        i+=1\n",
    "    return batch_x, batch_y, batch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (self.feed('data')\n",
    "#         .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "#         .lrn(2, 2e-05, 0.75, name='norm1')\n",
    "#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "#         .conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "#         .lrn(2, 2e-05, 0.75, name='norm2')\n",
    "#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "#         .conv(3, 3, 384, 1, 1, name='conv3')\n",
    "#         .conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "#         .conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "#         .fc(4096, name='fc6')\n",
    "#         .fc(4096, name='fc7')\n",
    "#         .fc(n_classes, relu=False, name='fc8')\n",
    "#         .softmax(name='prob'))\n",
    "\n",
    "\n",
    "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
    "    '''From https://github.com/ethereon/caffe-tensorflow\n",
    "    '''\n",
    "    c_i = input.get_shape()[-1]\n",
    "    assert c_i%group==0\n",
    "    assert c_o%group==0\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)   \n",
    "    \n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        input_groups = tf.split(3, group, input)\n",
    "        kernel_groups = tf.split(3, group, kernel)\n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat(3, output_groups)\n",
    "    return  tf.reshape(tf.nn.bias_add(conv, biases), [-1]+conv.get_shape().as_list()[1:])\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    \n",
    "    #conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "    k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\n",
    "    conv1_in = conv(x, weights['conv1W'], biases['conv1b'], k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
    "    conv1 = tf.nn.relu(conv1_in)\n",
    "\n",
    "    #lrn(2, 2e-05, 0.75, name='norm1')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
    "\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "    #conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "    k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv2_in = conv(maxpool1, weights['conv2W'], biases['conv2b'], k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv2 = tf.nn.relu(conv2_in)\n",
    "    \n",
    "    #lrn(2, 2e-05, 0.75, name='norm2')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
    "    \n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool2')                                                  \n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #conv(3, 3, 384, 1, 1, name='conv3')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\n",
    "    conv3_in = conv(maxpool2, weights['conv3W'], biases['conv3b'], k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv3 = tf.nn.relu(conv3_in)\n",
    "    \n",
    "    #conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\n",
    "    conv4_in = conv(conv3, weights['conv4W'], biases['conv4b'], k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv4 = tf.nn.relu(conv4_in)\n",
    "    \n",
    "    #conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "    k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv5_in = conv(conv4, weights['conv5W'], biases['conv5b'], k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv5 = tf.nn.relu(conv5_in)\n",
    "    \n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "    #fc(4096, name='fc6')\n",
    "    fc6 = tf.nn.relu_layer(tf.reshape(maxpool5, [-1, int(prod(maxpool5.get_shape()[1:]))]), weights['fc6W'], biases['fc6B'])\n",
    "    fc6 = tf.nn.dropout(fc6, dropout)\n",
    "    \n",
    "    #fc(4096, name='fc7')\n",
    "    fc7 = tf.nn.relu_layer(fc6, weights['fc7W'], biases['fc7B'])\n",
    "    fc7 = tf.nn.dropout(fc7, dropout)\n",
    "    \n",
    "    #fc(n_classes, relu=False, name='fc8')\n",
    "    fc8 = tf.nn.xw_plus_b(fc7, weights['fc8W'], biases['fc8B'])\n",
    "    \n",
    "    return fc8\n",
    "\n",
    "def getFeat(x):\n",
    "    return prob(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {    \n",
    "    'conv1W': tf.Variable(net_data[\"conv1\"][0], name=\"c1w\"),\n",
    "    'conv2W': tf.Variable(net_data[\"conv2\"][0], name=\"c2w\"),\n",
    "    'conv3W': tf.Variable(net_data[\"conv3\"][0], name=\"c3w\"),\n",
    "    'conv4W': tf.Variable(net_data[\"conv4\"][0], name=\"c4w\"),\n",
    "    'conv5W': tf.Variable(net_data[\"conv5\"][0], name=\"c5w\"),\n",
    "    'fc6W': tf.Variable(net_data[\"fc6\"][0], name=\"fc6w\"),\n",
    "    'fc7W': tf.Variable(net_data[\"fc7\"][0], name=\"fc7w\"),\n",
    "    'fc8W': tf.Variable(net_data[\"fc8\"][0], name=\"fc8w\")\n",
    "}\n",
    "\n",
    "biases = {    \n",
    "    'conv1b': tf.Variable(net_data[\"conv1\"][1], name=\"c1b\"),\n",
    "    'conv2b': tf.Variable(net_data[\"conv2\"][1], name=\"c2b\"),\n",
    "    'conv3b': tf.Variable(net_data[\"conv3\"][1], name=\"c3b\"),\n",
    "    'conv4b': tf.Variable(net_data[\"conv4\"][1], name=\"c4b\"),\n",
    "    'conv5b': tf.Variable(net_data[\"conv5\"][1], name=\"c5b\"),\n",
    "    'fc6B': tf.Variable(net_data[\"fc6\"][1], name=\"fc6b\"),\n",
    "    'fc7B': tf.Variable(net_data[\"fc7\"][1], name=\"fc7b\"),\n",
    "    'fc8B': tf.Variable(net_data[\"fc8\"][1], name=\"fc8b\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None,) + xdim) # None = number of input images\n",
    "y = tf.placeholder(tf.float32, [None,ydim])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "# Construct model\n",
    "prob = conv_net(x, weights, biases, keep_prob)\n",
    "feat = tf.nn.softmax(prob) # subtract max\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prob, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify\n",
    "batch_size = 25\n",
    "ImgPath = \"/ImgDir/\"\n",
    "files = [f for f in listdir(ImgPath) if isfile(join(ImgPath, f))]\n",
    "training_iters = len(files)\n",
    "init = tf.initialize_all_variables()\n",
    "labels = []\n",
    "names = []\n",
    "result = []\n",
    "test_acc = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1        \n",
    "    while step * batch_size < training_iters:    \n",
    "        batch_x, batch_y, batch_names = next_batch_not_rand(step,batch_size,files)        \n",
    "        labels.extend(batch_y)\n",
    "        result.extend(sess.run(prob, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "        names.extend(batch_names)\n",
    "        test_acc.append(sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "        #print test_acc\n",
    "        step += 1\n",
    "    print \"Test accuracy =  \" + \"{:.2f}%\".format(np.mean(test_acc)*100)\n",
    "    result_softmax = softmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the images with highest probability\n",
    "bests = np.argmax(result_softmax,axis = 0)\n",
    "print bests\n",
    "print \"best cat: \" + names[bests[0]] + \" label \" + str(labels[bests[0]])\n",
    "im = (imread(ImgPath + names[bests[0]])[:,:,:3])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(im)    \n",
    "plt.show() \n",
    "print \"best dog: \" + names[bests[1]] + \" label \" + str(labels[bests[1]])\n",
    "im = (imread(ImgPath + names[bests[1]])[:,:,:3])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(im)    \n",
    "plt.show() \n",
    "print \"best flower: \" + names[bests[2]] + \" label \" + str(labels[bests[2]])\n",
    "im = (imread(ImgPath + names[bests[2]])[:,:,:3])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(im)    \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the errors\n",
    "for ind in range(len(names)):\n",
    "    if argmax(result_softmax[ind,:]) != argmax(labels[ind]):\n",
    "        print names[ind] + \" \" + str(argmax(result_softmax[ind,:])) + \" \" + str(result_softmax[ind,:])\n",
    "        im = (imread(ImgPath + names[ind])[:,:,:3])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(im)    \n",
    "        plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
